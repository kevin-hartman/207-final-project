{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Malware Prediction\n",
    "W207 Final Project<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kevin Hartman<br>\n",
    "Gunnar Mein<br>\n",
    "Andrew Morris<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/microsoft-malware-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href='#Summary'>The Competition: Can you predict if a machine will soon be hit with malware?</a></li>\n",
    "    <li><a href='#Setup'>Definitions and Setup</a></li>\n",
    "    <li><a href='#Loading'>Loading the Data</a></li>\n",
    "    <li><a href='#EDA'>Exploratory Data Analysis</a></li>\n",
    "    <li><a href='#Cleaning'>Data Wrangling and Cleaning</a></li>\n",
    "    <li><a href='#Preprocessing'>Encoding and Transformations</a></li>\n",
    "    <li><a href='#Features'>Feature Selection</a></li>\n",
    "    <li><a href='#Models'>Model Fitting and Evaluation</a></li>\n",
    "    <li><a href='#Conclusion'>Review and Conclusion</a></li>\n",
    "    <li><a href='#Appendix'>Appendix</a></li>\n",
    "</ol>\n",
    "\n",
    "We used the following classifiers that were covered in the course:\n",
    "\n",
    "- **k Nearest Neighbors** (week 2)\n",
    "- **Decision Trees**, as well as **Random Forests**, **AdaBoost**, and **Gradient Boosting** (week 4)\n",
    "- **Logistic Regression** (week 5)\n",
    "- **Neural Networks** (week 7)\n",
    "- **PCA and Gaussian Mixture Models** (weeks 9 and 10)\n",
    "\n",
    "\n",
    "We did not pursue Naive Bayes (week 3), Stochastic Gradient Descent (week 6) or Support Vector Machines (week 8)*, or due to time constraints, and because our EDA did not provide enough support to investigate these approaches.\n",
    "\n",
    "\\* Of note, I did run very limited LinearSVM() but the results showed the model just basically guessed all positives or all negatives and it was always half-right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The Competition: Can you predict if a machine will soon be hit with malware?\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a bunch of libraries.\n",
    "\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #hide warnings that arise from missing glyphs, deprecations, etc.\n",
    "\n",
    "#\n",
    "# set some global flags\n",
    "#\n",
    "\n",
    "do_EDA = False    # EDA portion can be skipped if working further downstream\n",
    "debug = True      # use small files to check basic functionality\n",
    "save_data = False # not saving encoded files can save a lot of time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "Utility function for loading, and the actual load calls deciding betwen small debug versions\n",
    "and the 4GB real files\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load with pre-informed data types for faster loading\n",
    "\n",
    "def load_from_raw_data(filename, cleaning=True):\n",
    "    dtypes_for_EDA = {\n",
    "        'MachineIdentifier':                                    'str',\n",
    "        'ProductName':                                          'str',\n",
    "        'EngineVersion':                                        'str',\n",
    "        'AppVersion':                                           'str',\n",
    "        'AvSigVersion':                                         'str',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float64',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int16',\n",
    "        'Platform':                                             'str',\n",
    "        'Processor':                                            'str',\n",
    "        'OsVer':                                                'str',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'str',\n",
    "        'OsBuildLab':                                           'str',\n",
    "        'SkuEdition':                                           'str',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'str',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'str',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float64', \n",
    "        'Census_MDC2FormFactor':                                'str',\n",
    "        'Census_DeviceFamily':                                  'str',\n",
    "        'Census_OEMNameIdentifier':                             'float32', \n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32', \n",
    "        'Census_ProcessorClass':                                'str',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float64', \n",
    "        'Census_PrimaryDiskTypeName':                           'str',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float64', \n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'str',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32', \n",
    "        'Census_PowerPlatformRoleName':                         'str',\n",
    "        'Census_InternalBatteryType':                           'str',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float64', \n",
    "        'Census_OSVersion':                                     'str',\n",
    "        'Census_OSArchitecture':                                'str',\n",
    "        'Census_OSBranch':                                      'str',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'str',\n",
    "        'Census_OSSkuName':                                     'str',\n",
    "        'Census_OSInstallTypeName':                             'str',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'str',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'str',\n",
    "        'Census_ActivationChannel':                             'str',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'str',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "    \n",
    "    dtypes_for_cleaning = {\n",
    "        'MachineIdentifier':                                    'str',\n",
    "        'ProductName':                                          'str',\n",
    "        'EngineVersion':                                        'str',\n",
    "        'AppVersion':                                           'str',\n",
    "        'AvSigVersion':                                         'str',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float64',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int16',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'str',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float64', \n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float32', \n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32', \n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float64', \n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float64', \n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'str',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32', \n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'str',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float64', \n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'str',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "    df = pd.read_csv(filename, dtype=dtypes_for_cleaning if cleaning else dtypes_for_EDA, engine='c')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# here is where we decide what to load, and trigger the process\n",
    "#\n",
    "if debug:\n",
    "    filename_train = \"data/debug/mini_initial.csv\"\n",
    "    filename_test = \"data/debug/mini_initial_test.csv\"\n",
    "else:\n",
    "    filename_train = \"data/train.csv\"\n",
    "    filename_test = \"data/test.csv\"\n",
    "    \n",
    "train_df = load_from_raw_data(filename_train) \n",
    "test_df = load_from_raw_data(filename_test)\n",
    "full_df = pd.concat([train_df, test_df]) # make full, big dataframe for analysis\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>\n",
    "\n",
    "Analysis class for seaborn plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom-made class to assist with EDA on this dataset\n",
    "# The code is generalizable. However, specific decisions on plot types were made because\n",
    "# all our features are categorical\n",
    "class Analyze:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def print_eda_summary(self):\n",
    "        #sns.set(rc={'figure.figsize':(10*2,16*8)})\n",
    "        sns.set()\n",
    "        i=0\n",
    "        fig, ax = plt.subplots(nrows=round(len(self.df.columns)), ncols=2, figsize=(16,5*round(len(self.df.columns))))\n",
    "        all_cols=[]\n",
    "        for col in self.df.columns:\n",
    "            #if col == 'MachineIdentifier': continue\n",
    "            all_cols.append(col)\n",
    "            max_len = self.df[col].nunique()\n",
    "            if max_len > 10:\n",
    "                max_len = 10\n",
    "            g=sns.countplot(y=self.df[col].fillna(-1), hue=self.df['HasDetections'], order=self.df[col].fillna(-1).value_counts(dropna=False).iloc[:max_len].index, ax=ax[i][0])\n",
    "            g.set_xlim(0,self.df.shape[0])\n",
    "            plt.tight_layout()\n",
    "            ax[i][0].title.set_text(col)\n",
    "            ax[i][0].xaxis.label.set_visible(False)\n",
    "            xlabels = ['{:,.0f}'.format(x) + 'K' for x in g.get_xticks()/1000]\n",
    "            g.set_xticklabels(xlabels)\n",
    "            ax[i][1].axis(\"off\")\n",
    "            # Basic info\n",
    "            desc = self.df[col].describe()\n",
    "            summary = \"DESCRIPTION\\n   Name: {:}\\n   Type: {:}\\n  Count: {:}\\n Unique: {:}\\nMissing: {:}\\nPercent: {:2.3f}\".format(\n",
    "                desc.name.ljust(50), str(desc.dtype).ljust(10), self.df[col].count(), self.df[col].nunique(),\n",
    "                ('yes' if self.df[col].hasnans else 'no'), (1-self.df[col].count()/self.df.shape[0])*100)\n",
    "            ax[i][1].text(0, 1, summary, verticalalignment=\"top\", family='monospace', fontsize=12)\n",
    "            analysis=[]\n",
    "            if self.df[col].dtype.name == 'object': \n",
    "                # additional analysis for categorical variables\n",
    "                if len(self.df[col].str.lower().unique()) != len(self.df[col].unique()):\n",
    "                    analysis.append(\"- duplicates from case\\n\")\n",
    "                # look for HTML escape characters (&#x..;)\n",
    "                # and unicode characters (searching for: anything not printable)\n",
    "                self.df_bad = self.df[col][self.df[col].str.contains(r'[\\x00-\\x1f]|&#x\\d\\d;', regex=True, na=True)]\n",
    "                if len(self.df_bad) - self.df.shape[0] - self.df[col].count()>0:\n",
    "                    analysis.append(\"- illegal chars: {:}\\n\".format(len(self.df_bad) - self.df.shape[0] - self.df[col].count()))\n",
    "                # find different capitalizations of \"unknown\"\n",
    "                # if more than one present, need to read as string, turn to lowercase, then make categorical\n",
    "                self.df_unknown = self.df[col].str.lower() == 'unknown'\n",
    "                unknowns = self.df[col][self.df_unknown].unique()\n",
    "                if len(unknowns) > 1:\n",
    "                    analysis.append(\"- unknowns\\n  {:}\\n\".format(unknowns))\n",
    "                self.df[col] = self.df[col].astype('category')\n",
    "                if len(''.join(analysis)) > 0:\n",
    "                    ax[i][1].text(.5, .85, 'FINDINGS\\n'+''.join(analysis), verticalalignment=\"top\", family='monospace', fontsize=12)\n",
    "            else:\n",
    "                # Stats for numeric variables\n",
    "                statistics = \"STATS\\n   Mean: {:5.4g}\\n    Std: {:5.4g}\\n    Min: {:5.4g}\\n    25%: {:5.4g}\\n    50%: {:5.4g}\\n    75%: {:5.4g}\\n    Max: {:5.4g}\".format(\n",
    "                    desc.mean(), desc.std(), desc.min(), desc.quantile(.25), desc.quantile(.5), desc.quantile(.75), desc.max())\n",
    "                ax[i][1].text(.5, .85, statistics, verticalalignment=\"top\", family='monospace', fontsize=12)\n",
    "\n",
    "            # Top 5 and bottom 5 unique values or all unique values if < 10\n",
    "            if self.df[col].nunique() <= 10:\n",
    "                values = pd.DataFrame(list(zip(self.df[col].value_counts(dropna=False).keys().tolist(),\n",
    "                                         self.df[col].value_counts(dropna=False).tolist())),\n",
    "                                columns=['VALUES', 'COUNTS'])\n",
    "                values = values.to_string(index=False)\n",
    "                ax[i][1].text(0, .6, values, verticalalignment=\"top\", family='monospace', fontsize=12)\n",
    "            else:\n",
    "                values = pd.DataFrame(list(zip(self.df[col].value_counts(dropna=False).iloc[:5].keys().tolist(),\n",
    "                                         self.df[col].value_counts(dropna=False).iloc[:5].tolist())),\n",
    "                                columns=['VALUES', 'COUNTS'])\n",
    "                mid_row = pd.DataFrame({'VALUES':[\":\"],\n",
    "                                        'COUNTS':[\":\"]})\n",
    "                bot_values = pd.DataFrame(list(zip(self.df[col].value_counts(dropna=False).iloc[-5:].keys().tolist(),\n",
    "                                         self.df[col].value_counts(dropna=False).iloc[-5:].tolist())),\n",
    "                                columns=['VALUES', 'COUNTS'])\n",
    "                values = values.append(mid_row)\n",
    "                values = values.append(bot_values)\n",
    "                values = values.to_string(index=False)\n",
    "                ax[i][1].text(0, .6, values, verticalalignment=\"top\", family='monospace', fontsize=12)\n",
    "            i=i+1\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Needed for some of the analysis work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, df): #in_file):\n",
    "        self.df = df #pd.read_csv(in_file, dtype=dtypes)\n",
    "        #print(\"Completed read operation for\", in_file)\n",
    "        #self.reduce_mem()\n",
    "        gc.collect()\n",
    "        self.make_subsets(self.df)\n",
    "        self.encode_it()\n",
    "        self.transform_df(self.df, self.nominal_cols)\n",
    "        self.std_norm()\n",
    "        \n",
    "    \n",
    "    def reduce_mem(self, verbose=True):\n",
    "        start_mem = self.df.memory_usage().sum() / 1024**2\n",
    "        print('-- attempting to reduce memory. memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            col_type = self.df[col].dtype\n",
    "\n",
    "            if col_type != object and str(col_type) != 'category':\n",
    "                c_min = self.df[col].min()\n",
    "                c_max = self.df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int64)  \n",
    "                # leave floats alone because the downcasting is messing up our mapped values\n",
    "                #else:\n",
    "                #    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                #        df[col] = df[col].astype(np.float16)\n",
    "                #    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                #        df[col] = df[col].astype(np.float32)\n",
    "                #    else:\n",
    "                #        df[col] = df[col].astype(np.float64)\n",
    "                else:\n",
    "                    if str(col_type)[:5] != 'float':\n",
    "                        self.df[col] = self.df[col].astype('category')\n",
    "\n",
    "        end_mem = self.df.memory_usage().sum() / 1024**2\n",
    "        print('-- memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        print('-- decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def make_subsets(self, df):\n",
    "        print(\"-- making subsets ...\")\n",
    "        numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        self.numeric_cols = [c for c,v in self.df.dtypes.items() if v in numerics and c in self.df.columns]\n",
    "        self.nominal_cols = [c for c in self.df.columns if (c not in self.numeric_cols)]\n",
    "#         # Andrew - still need to fix this\n",
    "#         self.nominal_cols.remove('SmartScreen')\n",
    "        self.binary_cols = [c for c in self.df.columns if (self.df[c].nunique() == 2 and c not in self.nominal_cols)]\n",
    "        self.unary_cols = [c for c in self.df.columns if (self.df[c].nunique() == 1 and c not in self.nominal_cols)]\n",
    "        if \"HasDetections\" in df.columns:\n",
    "            self.labels = df[\"HasDetections\"].values\n",
    "        print(\"-- subsets are complete\")\n",
    "        return\n",
    "\n",
    "    def transform_df(self, in_df, nominal_cols):\n",
    "        print(\"-- datatype transformation ...\")\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        tmp_df = in_df[nominal_cols].apply(le.fit_transform)\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int8].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int16].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int32].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int64].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float16].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float32].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float64].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df[in_df.select_dtypes(bool).columns]:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        self.df = tmp_df\n",
    "        print(\"-- completed transforming dtypes\")\n",
    "        return\n",
    "\n",
    "    def std_norm(self):\n",
    "        print(\"-- scaling ...\")\n",
    "        col_to_std = ['AVProductStatesIdentifier',\n",
    "                      'CountryIdentifier',\n",
    "                      'CityIdentifier',\n",
    "                      'GeoNameIdentifier',\n",
    "                      'LocaleEnglishNameIdentifier',\n",
    "                      'OsBuild',\n",
    "                      'IeVerIdentifier',\n",
    "                      'Census_OEMNameIdentifier',\n",
    "                      'Census_OEMModelIdentifier',\n",
    "                      'Census_ProcessorCoreCount',\n",
    "                      'Census_ProcessorModelIdentifier',\n",
    "                      'Census_PrimaryDiskTotalCapacity',\n",
    "                      'Census_SystemVolumeTotalCapacity',\n",
    "                      'Census_TotalPhysicalRAM',\n",
    "                      'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "                      'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "                      'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "                      'Census_InternalBatteryNumberOfCharges',\n",
    "                      'Census_OSBuildNumber',\n",
    "                      'Census_OSInstallLanguageIdentifier',\n",
    "                      'Census_OSUILocaleIdentifier',\n",
    "                      'Census_FirmwareManufacturerIdentifier',\n",
    "                      'Census_FirmwareVersionIdentifier',\n",
    "                      'Wdft_RegionIdentifier',\n",
    "                      'OsBuildLab_major',\n",
    "                      'OsBuildLab_minor',\n",
    "                      'OsBuildLab_platform',\n",
    "                      'OsBuildLab_release',\n",
    "                      'OsBuildLab_build2']\n",
    "        scaled_features = self.df.copy()\n",
    "        features = scaled_features[col_to_std]\n",
    "        scaler = StandardScaler().fit(features.values)\n",
    "        features = scaler.transform(features.values)\n",
    "        scaled_features[col_to_std] = features\n",
    "        self.df = scaled_features\n",
    "        print(\"-- completed standardization and normalization\")\n",
    "        return\n",
    "    \n",
    "    def encode_it(self):\n",
    "        print(\"-- label encoding ...\")\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for n in self.nominal_cols:\n",
    "            #print(\" ...\",n)\n",
    "            self.df[n] = le.fit_transform(self.df[n])\n",
    "        print(\"-- completed label encoding\")\n",
    "        return\n",
    "    \n",
    "    def get_encoded_data(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a mini set from the supplied criteria (n, features, labels)\n",
    "def generate_mini(n, features, labels):\n",
    "    sample_size = n / features.shape[0]\n",
    "    reserved_size = 1-sample_size\n",
    "    X_mini, X_rest, y_mini, y_rest = train_test_split(features, labels, stratify=labels, test_size=reserved_size, random_state=0)\n",
    "    return X_mini, X_rest, y_mini, y_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create stratified train, dev and validate sets from supplied ratios \n",
    "def generate_train_dev_validate_sets(train_ratio, test_ratio, features, labels):\n",
    "    reserved_size = 1-train_ratio\n",
    "    X_train, X_rest, y_train, y_rest =  \\\n",
    "        train_test_split(features, labels, stratify=labels, test_size=reserved_size, random_state=0)\n",
    "    reserved_size = 1 - (test_ratio / reserved_size)\n",
    "    X_dev, X_validate, y_dev, y_validate = \\\n",
    "        train_test_split(X_rest, y_rest, stratify=y_rest, test_size=reserved_size, random_state=0)\n",
    "    return X_train, X_dev, X_validate, y_train, y_dev, y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function for saving encoded frames\n",
    "#\n",
    "def save_encoded_files(df, name):\n",
    "    \n",
    "    # save the file\n",
    "    df.to_csv(\"data/\"+name+\"_encoded.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for generating our dtypes for loading the file back when we need it\n",
    "def dump_final_types(df):\n",
    "    for dtype in df.dtypes.items():\n",
    "        print(\"'{:} '{:}',\".format((dtype[0] + \"':\").ljust(54), dtype[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_EDA:\n",
    "    test_df['HasDetections'] = np.int8(2) # fake labels for test data\n",
    "    \n",
    "    analyzer = Analyze(full_df)\n",
    "    analyzer.print_eda_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: (to inform further cleaning)\n",
    "* Fields with largely missing values:\n",
    " * PuaMode - missing 99.9% of the data - remove\n",
    " * Census_ProcessorClass - 99.5% missing - remove\n",
    " * DefaultBrowsersIdentifier - 95% missing - probably would correlate well with malware but its all missing - remove \n",
    " * Census_IsFlightingInternal - 83 missing (21 are 1s and rest are 0) - remove\n",
    " * Census_InternalBatteryType - 70% missing - battery correlates to malware how? - remove\n",
    "* Binary fields\n",
    " * Census_IsWIMBootEnabled - It is 0 or missing. One value is set to 1. Recode the 1 as a \"missing\" and make this a binary field?\n",
    " * Census_IsFlightsDisabled - Mostly 0s. 2% are missing. 88 are 1s. Recode the 1 as \"missing\" and then it becomes a binary field?\n",
    " * Census_IsPortableOperatingSystem - Mostly 0s - remove\n",
    " * IsBeta - mostly 0s. 67 are 1s. - remove\n",
    " * AutoSampleOptIn - Mostly 0s. - remove\n",
    "* Other fields\n",
    " * UacLuaenable - Mostly 1s. Zero out the rest and turn into a binary field.\n",
    " * AvProductsInstalled - Bin 4,5,6 and 7 into one bin. Move 0 and the missings together.\n",
    " * AvProductsEnabled - Bin 4 and 5 together. \n",
    " * RtpStateBitField - Bin 3, 1 and 35 together with the missing category.\n",
    " * SmartScreen - Bin the garbage and low frequency values with the missing category. Correct spellings on the others.\n",
    " * Census_ProcessorCoreCount - could bin but need to probe in further to see how\n",
    " * Census_ProcessorManufacturerIdentifier - bin 10, 3, 9, 7 and 4 with the missing category.\n",
    " * Census_InternalPrimaryDiagonalDisplaySizeInInches - bin these by real inches w/o the fractions - need to probe in further\n",
    " * Census_InternalPrimaryDisplayResolutionHorizontal - same as above\n",
    " * Census_InternalPrimaryDisplayResolutionVertical - same as above\n",
    " * Census_GenuineStateName - Bin TAMPERED with UNKNOWN\n",
    " * Census_FlightRing - Bin Invalid with Unknown\n",
    " * Census_PrimaryDiskTotalCapacity - Bin this by range?\n",
    " * Census_SystemVolumeTotalCapacity - Same as above\n",
    " * Census_TotalPhysicalRam - Same as above\n",
    " * Census_ChassisTypeName - Look into binning\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):  \n",
    "    \n",
    "    #\n",
    "    # drop certain useless columns\n",
    "    #\n",
    "    \n",
    "    df = df.drop(columns=['PuaMode','Census_ProcessorClass'])\n",
    "    \n",
    "    #\n",
    "    # make all strings lower case\n",
    "    # get rid of hex char codes, keep the actual code number\n",
    "    #\n",
    "    \n",
    "    char_treatment = [\n",
    "        'AvSigVersion',\n",
    "        'SmartScreen',\n",
    "        'Census_InternalBatteryType'\n",
    "    ]\n",
    "    \n",
    "    case_treatment = [\n",
    "        'SmartScreen',\n",
    "        'Census_ChassisTypeName',\n",
    "        'Census_OSEdition',\n",
    "        'Census_PowerPlatformRoleName',\n",
    "        'Census_GenuineStateName'\n",
    "    ]\n",
    "    \n",
    "    print(\"-- replacing weird characters ...\")\n",
    "    for col in char_treatment:\n",
    "        if df[col].dtype.name == 'object':\n",
    "            df[col] = df[col].str.replace(r'&#x(\\d\\d);', '\\1', regex=True)\n",
    "            df[col] = df[col].str.replace(r'[\\x00-\\x1f]', '', regex=True)\n",
    "        else:\n",
    "            print(\"col\", col,\"flagged for char replacement is not of type string\")\n",
    "            \n",
    "    print(\"-- lower-casing where appropriate ...\")\n",
    "    for col in case_treatment:\n",
    "        if df[col].dtype.name == 'object':\n",
    "            df[col] = df[col].str.lower()\n",
    "             \n",
    "    #\n",
    "    # Fix SmartScreen discrepencies\n",
    "    # TODO: Decide what to do with the garbage fields\n",
    "    #           \n",
    "    df.replace({'SmartScreen':\n",
    "        {'Enabled':'on',\n",
    "         'RequiredAdmin':'requireadmin',\n",
    "         'of':'off',\n",
    "         'Promt':'prompt',\n",
    "         'Promprt':'prompt'}})\n",
    "            \n",
    "    #\n",
    "    # make strings into categories\n",
    "    #\n",
    "    \n",
    "    categories = [\n",
    "        'SmartScreen',\n",
    "        'Census_InternalBatteryType',\n",
    "        'Census_ChassisTypeName',\n",
    "        'Census_OSEdition'\n",
    "    ]\n",
    "    \n",
    "    print(\"-- making categories from strings that needed massaging ...\")\n",
    "    for col in categories:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "\n",
    "        \n",
    "    #\n",
    "    # add 'unknown' categories where necessary and replace the NAs\n",
    "    # ADD COLUMNS NAMES HERE TO HAVE THEIR CATEGORIES AUGMENTED AND NAS FILLED WITH 'unknown'\n",
    "    #\n",
    "    \n",
    "    categories = [\n",
    "        'SmartScreen',\n",
    "        'Census_PrimaryDiskTypeName',  # ['HDD' 'SSD' 'UNKNOWN' 'Unspecified']\n",
    "        'Census_InternalBatteryType',\n",
    "        'Census_OSEdition',\n",
    "        'Census_PowerPlatformRoleName', # also had 'unknown' as well as Nas\n",
    "        'Census_GenuineStateName',       # and this one too\n",
    "        'Census_ChassisTypeName'\n",
    "        \n",
    "    ]\n",
    "\n",
    "    print(\"-- adding categories ..\")\n",
    "    for col in categories:\n",
    "        print(\"   \", col)\n",
    "        if 'unknown' not in df[col].cat.categories:\n",
    "            df[col].cat.add_categories(['unknown'], inplace=True)\n",
    "        df[col].fillna('unknown', inplace=True)\n",
    "    # add one manually because it needs a special unknown value\n",
    "    df[\"OsBuildLab\"].cat.add_categories([\"0.0.-.-.0-0\"], inplace=True)\n",
    "    df[\"OsBuildLab\"].fillna(\"0.0.-.-.0-0\", inplace=True)\n",
    "    # and this one already had some 'unknown' values\n",
    "    #df['Census_ChassisTypeName'].fillna('unknown', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # flag and fill selected NAs\n",
    "    # ADD COLUMN NAMES HERE IN nafill TO HAVE COLUMNS FLAGGED AND FILLED WITH PROVIDED VALUES\n",
    "    #\n",
    "    \n",
    "    print(\"-- replacing selected NA values\")\n",
    "    nafill = {\n",
    "        \"RtpStateBitfield\":0,\n",
    "        \"DefaultBrowsersIdentifier\":0,\n",
    "        \"AVProductStatesIdentifier\":0,\n",
    "        \"AVProductsInstalled\":0,\n",
    "        \"AVProductsEnabled\":0,\n",
    "        \"CityIdentifier\":0,\n",
    "        \"OrganizationIdentifier\":0,\n",
    "        \"GeoNameIdentifier\":0,\n",
    "        \"IsProtected\":0,\n",
    "        \"SMode\":0,\n",
    "        \"IeVerIdentifier\":0,\n",
    "        \"Firewall\":0,\n",
    "        \"UacLuaenable\":0,\n",
    "        \"Census_OEMNameIdentifier\":0,\n",
    "        \"Census_OEMModelIdentifier\":0,\n",
    "        \"Census_ProcessorCoreCount\":0,\n",
    "        \"Census_ProcessorManufacturerIdentifier\":0,\n",
    "        \"Census_ProcessorModelIdentifier\":0,\n",
    "        \"Census_PrimaryDiskTotalCapacity\":0,\n",
    "        \"Census_SystemVolumeTotalCapacity\":0,\n",
    "        \"Census_TotalPhysicalRAM\":0,\n",
    "        \"Census_InternalPrimaryDiagonalDisplaySizeInInches\":0,\n",
    "        \"Census_InternalPrimaryDisplayResolutionHorizontal\":0,\n",
    "        \"Census_InternalPrimaryDisplayResolutionVertical\":0,\n",
    "        \"Census_InternalBatteryNumberOfCharges\":0,\n",
    "        \"Census_OSInstallLanguageIdentifier\":0,\n",
    "        \"Census_IsFlightingInternal\":0,\n",
    "        \"Census_IsFlightsDisabled\":0,\n",
    "        \"Census_ThresholdOptIn\":0,\n",
    "        \"Census_FirmwareManufacturerIdentifier\":0,\n",
    "        \"Census_IsWIMBootEnabled\":0,\n",
    "        \"Census_IsVirtualDevice\":0,\n",
    "        \"Census_IsAlwaysOnAlwaysConnectedCapable\":0,\n",
    "        \"Wdft_IsGamer\":0,\n",
    "        \"Wdft_RegionIdentifier\":0,\n",
    "        \"Census_FirmwareVersionIdentifier\":0\n",
    "    }\n",
    "\n",
    "    for col in nafill:\n",
    "        df[col+'_wasna'] = df[col].isna()\n",
    "    df.fillna(value=nafill, inplace=True)\n",
    "    \n",
    "    #\n",
    "    # then some of these columns can become ints, not floats\n",
    "    #\n",
    "\n",
    "    print(\"-- converting columns to int ...\")\n",
    "    df['RtpStateBitfield'] = df['RtpStateBitfield'].astype(np.uint8)\n",
    "\n",
    "    #\n",
    "    # deal with version numbers\n",
    "    #\n",
    "    \n",
    "    print(\"-- mapping version numbers ...\")\n",
    "    def map_OsVer(df,col):\n",
    "        df_split = df[col].astype(str).str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000.0*df[col+'_major']+100.0*df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/1000.0\n",
    "\n",
    "    # e.g. 10.0.10240.16397\n",
    "    def map_CensusOSVersion(df,col):\n",
    "        df_split = df[col].astype(str).str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 1000000.0*df[col+'_major']+df[col+'_minor']*10000+(df[col+'_build1'])+(df[col+'_build2'])/100000.0\n",
    "\n",
    "    # e.g. 1.235.2586.0\n",
    "    def map_AvSigVersion(df,col):\n",
    "        df_split = df[col].astype(str).str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000.0*df[col+'_major']+df[col+'_minor']+(df[col+'_build1'])/10000.0+(df[col+'_build2'])/10000000.0\n",
    "\n",
    "\n",
    "    # e.g. 4.12.17007.18022\n",
    "    def map_AppVersion(df,col):\n",
    "        df_split = df[col].astype(str).str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000000.0*df[col+'_major']+100000.0 * df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/100000.0\n",
    "\n",
    "    # e.g. 1.1.12902.0\n",
    "    def map_EngineVersion(df,col):\n",
    "        df_split = df[col].astype(str).str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 100000000.0*df[col+'_major']+1000000.0*df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/10000.0\n",
    "\n",
    "    def map_OsBuildLab(df, col):\n",
    "        series = df[col].astype(str).str.replace('*', '.', regex=False)\n",
    "        df_split = series.str.split(\".\", n=4, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_platform'] = df_split[2].astype('category')\n",
    "        df[col+'_release'] = df_split[3].astype('category')\n",
    "        df_build = df_split[4].str.split(\"-\", n=1, expand=True)\n",
    "        df[col+'_build1'] = df_build[0].astype(np.int32)\n",
    "        df[col+'_build2'] = df_build[1].astype(np.int32)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 1000000.0*df['OsBuildLab_major']+10.0*df['OsBuildLab_minor']+df['OsBuildLab_build1']/100000.0+df['OsBuildLab_build2']/10000000000.0\n",
    "        df_split = None\n",
    "        df_build = None\n",
    "\n",
    "    map_EngineVersion(df, \"EngineVersion\")\n",
    "    map_AppVersion(df, \"AppVersion\")\n",
    "    map_AvSigVersion(df, \"AvSigVersion\")\n",
    "    map_CensusOSVersion(df, \"Census_OSVersion\")\n",
    "    map_OsVer(df, \"OsVer\")\n",
    "    map_OsBuildLab(df, \"OsBuildLab\")    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- replacing weird characters ...\n",
      "-- lower-casing where appropriate ...\n",
      "-- making categories from strings that needed massaging ...\n",
      "-- adding categories ..\n",
      "    SmartScreen\n",
      "    Census_PrimaryDiskTypeName\n",
      "    Census_InternalBatteryType\n",
      "    Census_OSEdition\n",
      "    Census_PowerPlatformRoleName\n",
      "    Census_GenuineStateName\n",
      "    Census_ChassisTypeName\n",
      "-- replacing selected NA values\n",
      "-- converting columns to int ...\n",
      "-- mapping version numbers ...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this triggers the cleaning process\n",
    "#\n",
    "\n",
    "cleaned_df = clean_data(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>\n",
    "\n",
    "Raw notes:\n",
    "\n",
    "Encoding portion of wrangler and description of what we did and why we did it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "runs the encoder on the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- making subsets ...\n",
      "-- subsets are complete\n",
      "-- label encoding ...\n",
      "-- completed label encoding\n",
      "-- datatype transformation ...\n",
      "-- completed transforming dtypes\n",
      "-- scaling ...\n",
      "-- completed standardization and normalization\n"
     ]
    }
   ],
   "source": [
    "encoded_full_df = Encoder(cleaned_df).get_encoded_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the test and train segments back off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_df = encoded_full_df[encoded_full_df['HasDetections'] != 2]\n",
    "encoded_test_df = encoded_full_df[encoded_full_df['HasDetections'] == 2]\n",
    "encoded_test_df = encoded_test_df.drop(columns='HasDetections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "Create mini-train sets for model building (and optionally save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate stratified data sets using supplied ratios to create the sets\n",
    "df_train, df_dev, df_validate, train_labels, dev_labels, validate_labels = \\\n",
    "    generate_train_dev_validate_sets(.7, .15, encoded_train_df, encoded_train_df['HasDetections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create mini_ files for model development\n",
    "#\n",
    "mini_ratio = .05\n",
    "\n",
    "mini_train, remaining, mini_train_labels, remaining_labels = \\\n",
    "    generate_mini(df_train.shape[0]*mini_ratio, df_train, df_train['HasDetections'])\n",
    "\n",
    "mini_dev, remaining, mini_dev_labels, remaining_labels = \\\n",
    "    generate_mini(df_dev.shape[0]*mini_ratio, df_dev, df_dev['HasDetections'])\n",
    "\n",
    "mini_validate, remaining, mini_validate_labels, remaining_labels = \\\n",
    "    generate_mini(df_validate.shape[0]*mini_ratio, df_validate, df_validate['HasDetections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mini_train: (6999, 149)\n",
      "shape of mini_dev: (1500, 149)\n",
      "shape of mini_validate: (1500, 149)\n",
      "\n",
      "checking symmetric difference between mini_dev and mini_train: 8263\n",
      "-- total unique machine ids after recombining both sets: 8313\n",
      "-- original length of mini_dev + length of mini_train: 8499\n",
      "\n",
      "checking symmetric difference between mini_validate and mini_train: 8258\n",
      "-- total unique machine ids after recombining both sets: 8309\n",
      "-- original length of mini_validate + length of mini_train: 8499\n",
      "\n",
      "checking symmetric difference between mini_dev and mini_validate: 2955\n",
      "-- total unique machine ids after recombining both sets: 2973\n",
      "-- original length of mini_dev + length of mini_validate: 3000\n",
      "\n",
      "done making mini sets\n",
      "seconds elapsed: 2.649631977081299\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of mini_train:\",mini_train.shape)\n",
    "print(\"shape of mini_dev:\",mini_dev.shape)\n",
    "print(\"shape of mini_validate:\",mini_validate.shape)\n",
    "print(\"\\nchecking symmetric difference between mini_dev and mini_train:\", len(set(mini_train['MachineIdentifier']).symmetric_difference(mini_dev['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_train['MachineIdentifier'], mini_dev['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_dev + length of mini_train:\", mini_dev.shape[0] + mini_train.shape[0])\n",
    "print(\"\\nchecking symmetric difference between mini_validate and mini_train:\", len(set(mini_train['MachineIdentifier']).symmetric_difference(mini_validate['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_train['MachineIdentifier'], mini_validate['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_validate + length of mini_train:\", mini_validate.shape[0] + mini_train.shape[0])\n",
    "print(\"\\nchecking symmetric difference between mini_dev and mini_validate:\", len(set(mini_dev['MachineIdentifier']).symmetric_difference(mini_validate['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_dev['MachineIdentifier'], mini_validate['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_dev + length of mini_validate:\", mini_validate.shape[0] + mini_dev.shape[0])\n",
    "print(\"\\ndone making mini sets\")\n",
    "print(\"seconds elapsed:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# save encoded mini files\n",
    "# save function will add \"data/\" and \"_encoded.csv\"\n",
    "#\n",
    "\n",
    "if save_data:\n",
    "    print(\"saving mini_train_encoded ...\")\n",
    "    save_encoded_files(mini_train, \"mini_train\")\n",
    "    print(\"saving mini_dev_encoded ...\")\n",
    "    save_encoded_files(mini_dev, \"mini_dev\")\n",
    "    print(\"saving mini_validate_encoded ...\")\n",
    "    save_encoded_files(mini_validate, \"mini_validate\")\n",
    "    print(\"done saving mini files\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# save encoded full files\n",
    "# save function will add \"data/\" and \"_encoded.csv\"\n",
    "#\n",
    "\n",
    "if save_data:\n",
    "    print(\"saving train_encoded ...\")\n",
    "    save_encoded_files(df_train, \"train\")\n",
    "    print(\"done saving encoded train file\")\n",
    "\n",
    "    print(\"saving dev_encoded ...\")\n",
    "    save_encoded_files(df_dev, \"dev\")\n",
    "    print(\"done saving encoded dev file\")\n",
    "\n",
    "    print(\"saving validate_encoded ...\")\n",
    "    save_encoded_files(df_validate, \"validate\")\n",
    "    print(\"done saving encoded validate file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# save large test dataset\n",
    "#\n",
    "\n",
    "if save_data:\n",
    "    print(\"saving encoded large test data ...\")\n",
    "    save_encoded_files(encoded_test_df, \"test\")\n",
    "    print(\"done saving encoded files\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n",
    "    \n",
    "    print(\"done saving files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# first, erase the labels from dev and validation data\n",
    "#\n",
    "\n",
    "df_dev['HasDetections']=True\n",
    "df_validate['HasDetections']=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of Features using SelectFromModel\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done selecting features\n"
     ]
    }
   ],
   "source": [
    "fsel = ExtraTreesClassifier(n_estimators=100).fit(df_train, train_labels)\n",
    "model = SelectFromModel(fsel, prefit=True)\n",
    "X_train_data_new = model.transform(df_train)\n",
    "X_dev_data_new = model.transform(df_dev)\n",
    "X_validate_data_new = model.transform(df_validate)\n",
    "print('done selecting features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "One of our async lecturers said that his place of work usually ends up with logistic regression, because with a lot of data, it does almost as well as anything else. Well, we certainly have a lot of data. So here goes one of our initial models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with logistic regression: 50.3% accuracy\n"
     ]
    }
   ],
   "source": [
    "def score_log_reg(train_data, train_labels, test_data, test_labels):\n",
    "    lrc = LogisticRegression(solver='lbfgs', max_iter=150)\n",
    "    lrc.fit(X=train_data, y=train_labels)\n",
    "\n",
    "    # predict and score on the dev set\n",
    "    pred = lrc.predict(test_data)\n",
    "    return metrics.accuracy_score(y_true=test_labels, y_pred=pred)\n",
    "\n",
    "print (f\"Predicting with logistic regression: {100*score_log_reg(X_train_data_new, train_labels, X_validate_data_new,  validate_labels):0.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<a href='#Contents'>[Back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods for feature selection\n",
    "\n",
    "Selection of Features using correlation, corplot analysis, and Gunnar's incremental trick (->appendix)\n",
    "\n",
    "Selection of Features using PCA (with GMM) (-> appendix)\n",
    "\n",
    "Selection of Features using Ridge Regression (not sure if we want to include) (if so ->appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: rerun after encoding\n",
    "if do_EDA:\n",
    "    sns.set(rc={'figure.figsize':(50,50)})\n",
    "    sns.heatmap(encoded_full_df.corr(), cmap='RdBu_r', annot=True, center=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
