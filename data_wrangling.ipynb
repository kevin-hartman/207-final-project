{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a bunch of libraries.\n",
    "\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # default: False. if True, uses existing mini_initial.csv file so this runs fast\n",
    "save_data = True # default: True. if False, will not save, which takes the most time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This loads the data and forces certain types\n",
    "#\n",
    "def load_data(filename):\n",
    "    \n",
    "    dtypes = {\n",
    "        'MachineIdentifier':                                    'str',\n",
    "        'ProductName':                                          'str',\n",
    "        'EngineVersion':                                        'str',\n",
    "        'AppVersion':                                           'str',\n",
    "        'AvSigVersion':                                         'str',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float64',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int16',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'str',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float64', \n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float32', \n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32', \n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float64', \n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float64', \n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'str',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32', \n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32', \n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'str',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float64', \n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'str',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n",
    "\n",
    "    df = pd.read_csv(\"data/\"+filename+\".csv\", dtype=dtypes, engine='c')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "        \n",
    "    # drop machine identifiers, so models don't train on them\n",
    "#     if \"MachineIdentifier\" in df.columns:\n",
    "#         df = df.drop(columns=[\"MachineIdentifier\"])\n",
    "    \n",
    "    #\n",
    "    # make all strings lower case\n",
    "    # get rid of hex char codes, keep the actual code number\n",
    "    #\n",
    "    \n",
    "    char_treatment = [\n",
    "        'AvSigVersion',\n",
    "        'SmartScreen',\n",
    "        'Census_InternalBatteryType'\n",
    "    ]\n",
    "    \n",
    "    case_treatment = [\n",
    "        'SmartScreen',\n",
    "        'Census_ChassisTypeName',\n",
    "        'Census_OSEdition',\n",
    "        'Census_PowerPlatformRoleName',\n",
    "        'Census_GenuineStateName'\n",
    "    ]\n",
    "    \n",
    "    print(\"-- replacing weird characters ...\")\n",
    "    for col in char_treatment:\n",
    "        if df[col].dtype.name == 'object':\n",
    "            df[col] = df[col].str.replace(r'&#x(\\d\\d);', '\\1', regex=True)\n",
    "            df[col] = df[col].str.replace(r'[\\x00-\\x1f]', '', regex=True)\n",
    "            \n",
    "    print(\"-- lower-casing where appropriate ...\")\n",
    "    for col in case_treatment:\n",
    "        if df[col].dtype.name == 'object':\n",
    "            df[col] = df[col].str.lower()\n",
    "            \n",
    "    #\n",
    "    # make strings into categories\n",
    "    #\n",
    "    \n",
    "    categories = [\n",
    "        'SmartScreen',\n",
    "        'Census_InternalBatteryType',\n",
    "        'Census_ChassisTypeName',\n",
    "        'Census_OSEdition'\n",
    "    ]\n",
    "    \n",
    "    print(\"-- making categories from strings that needed massaging ...\")\n",
    "    for col in categories:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "\n",
    "        \n",
    "    #\n",
    "    # add 'unknown' categories where necessary and replace the NAs\n",
    "    # ADD COLUMNS NAMES HERE TO HAVE THEIR CATEGORIES AUGMENTED AND NAS FILLED WITH 'unknown'\n",
    "    #\n",
    "    \n",
    "    categories = [\n",
    "        'PuaMode',\n",
    "        'SmartScreen',\n",
    "        'Census_ProcessorClass',\n",
    "        'Census_PrimaryDiskTypeName',  # ['HDD' 'SSD' 'UNKNOWN' 'Unspecified']\n",
    "        'Census_InternalBatteryType',\n",
    "        'Census_OSEdition',\n",
    "        'Census_PowerPlatformRoleName', # also had 'unknown' as well as Nas\n",
    "        'Census_GenuineStateName'       # and this one too\n",
    "        \n",
    "    ]\n",
    "\n",
    "    print(\"-- adding categories ..\")\n",
    "    for col in categories:\n",
    "        df[col].cat.add_categories(['unknown'], inplace=True)\n",
    "        df[col].fillna('unknown', inplace=True)\n",
    "    # add one manually because it needs a special unknown value\n",
    "    df[\"OsBuildLab\"].cat.add_categories([\"0.0.-.-.0-0\"], inplace=True)\n",
    "    df[\"OsBuildLab\"].fillna(\"0.0.-.-.0-0\", inplace=True)\n",
    "    # and this one already had some 'unknown' values\n",
    "    df['Census_ChassisTypeName'].fillna('unknown', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # flag and fill selected NAs\n",
    "    # ADD COLUMN NAMES HERE IN nafill TO HAVE COLUMNS FLAGGED AND FILLED WITH PROVIDED VALUES\n",
    "    #\n",
    "    \n",
    "    print(\"-- replacing selected NA values\")\n",
    "    nafill = {\n",
    "        \"RtpStateBitfield\":0,\n",
    "        \"DefaultBrowsersIdentifier\":0,\n",
    "        \"AVProductStatesIdentifier\":0,\n",
    "        \"AVProductsInstalled\":0,\n",
    "        \"AVProductsEnabled\":0,\n",
    "        \"CityIdentifier\":0,\n",
    "        \"OrganizationIdentifier\":0,\n",
    "        \"GeoNameIdentifier\":0,\n",
    "        \"IsProtected\":0,\n",
    "        \"SMode\":0,\n",
    "        \"IeVerIdentifier\":0,\n",
    "        \"Firewall\":0,\n",
    "        \"UacLuaenable\":0,\n",
    "        \"Census_OEMNameIdentifier\":0,\n",
    "        \"Census_OEMModelIdentifier\":0,\n",
    "        \"Census_ProcessorCoreCount\":0,\n",
    "        \"Census_ProcessorManufacturerIdentifier\":0,\n",
    "        \"Census_ProcessorModelIdentifier\":0,\n",
    "        \"Census_PrimaryDiskTotalCapacity\":0,\n",
    "        \"Census_SystemVolumeTotalCapacity\":0,\n",
    "        \"Census_TotalPhysicalRAM\":0,\n",
    "        \"Census_InternalPrimaryDiagonalDisplaySizeInInches\":0,\n",
    "        \"Census_InternalPrimaryDisplayResolutionHorizontal\":0,\n",
    "        \"Census_InternalPrimaryDisplayResolutionVertical\":0,\n",
    "        \"Census_InternalBatteryNumberOfCharges\":0,\n",
    "        \"Census_OSInstallLanguageIdentifier\":0,\n",
    "        \"Census_IsFlightingInternal\":0,\n",
    "        \"Census_IsFlightsDisabled\":0,\n",
    "        \"Census_ThresholdOptIn\":0,\n",
    "        \"Census_FirmwareManufacturerIdentifier\":0,\n",
    "        \"Census_IsWIMBootEnabled\":0,\n",
    "        \"Census_IsVirtualDevice\":0,\n",
    "        \"Census_IsAlwaysOnAlwaysConnectedCapable\":0,\n",
    "        \"Wdft_IsGamer\":0,\n",
    "        \"Wdft_RegionIdentifier\":0,\n",
    "        \"Census_FirmwareVersionIdentifier\":0\n",
    "    }\n",
    "\n",
    "    for col in nafill:\n",
    "        df[col+'_wasna'] = df[col].isna()\n",
    "    df.fillna(value=nafill, inplace=True)\n",
    "    \n",
    "    #\n",
    "    # then some of these columns can become ints, not floats\n",
    "    #\n",
    "\n",
    "    print(\"-- converting columns to int ...\")\n",
    "    df['RtpStateBitfield'] = df['RtpStateBitfield'].astype(np.uint8)\n",
    "\n",
    "    #\n",
    "    # deal with version numbers\n",
    "    #\n",
    "    \n",
    "    print(\"-- mapping version numbers ...\")\n",
    "    def map_OsVer(df,col):\n",
    "        df_split = df[col].str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000.0*df[col+'_major']+100.0*df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/1000.0\n",
    "\n",
    "    # e.g. 10.0.10240.16397\n",
    "    def map_CensusOSVersion(df,col):\n",
    "        df_split = df[col].str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 1000000.0*df[col+'_major']+df[col+'_minor']*10000+(df[col+'_build1'])+(df[col+'_build2'])/100000.0\n",
    "\n",
    "    # e.g. 1.235.2586.0\n",
    "    def map_AvSigVersion(df,col):\n",
    "        df_split = df[col].str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000.0*df[col+'_major']+df[col+'_minor']+(df[col+'_build1'])/10000.0+(df[col+'_build2'])/10000000.0\n",
    "\n",
    "\n",
    "    # e.g. 4.12.17007.18022\n",
    "    def map_AppVersion(df,col):\n",
    "        df_split = df[col].str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 10000000.0*df[col+'_major']+100000.0 * df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/100000.0\n",
    "\n",
    "    # e.g. 1.1.12902.0\n",
    "    def map_EngineVersion(df,col):\n",
    "        df_split = df[col].str.split(\".\", n=3, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_build1'] = df_split[2].astype(np.int16)\n",
    "        df[col+'_build2'] = df_split[3].astype(np.int16)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 100000000.0*df[col+'_major']+1000000.0*df[col+'_minor']+1.0*(df[col+'_build1'])+(df[col+'_build2'])/10000.0\n",
    "\n",
    "    def map_OsBuildLab(df, col):\n",
    "        series = df[col].str.replace('*', '.', regex=False)\n",
    "        df_split = series.str.split(\".\", n=4, expand=True)\n",
    "        df[col+'_major'] = df_split[0].astype(np.int16)\n",
    "        df[col+'_minor'] = df_split[1].astype(np.int16)\n",
    "        df[col+'_platform'] = df_split[2].astype('category')\n",
    "        df[col+'_release'] = df_split[3].astype('category')\n",
    "        df_build = df_split[4].str.split(\"-\", n=1, expand=True)\n",
    "        df[col+'_build1'] = df_build[0].astype(np.int32)\n",
    "        df[col+'_build2'] = df_build[1].astype(np.int32)\n",
    "        # the \"combined\" column is an attempt at making an orginal out of the four values\n",
    "        df[col+'_combined'] = 1000000.0*df['OsBuildLab_major']+10.0*df['OsBuildLab_minor']+df['OsBuildLab_build1']/100000.0+df['OsBuildLab_build2']/10000000000.0\n",
    "        df_split = None\n",
    "        df_build = None\n",
    "\n",
    "    map_EngineVersion(df, \"EngineVersion\")\n",
    "    map_AppVersion(df, \"AppVersion\")\n",
    "    map_AvSigVersion(df, \"AvSigVersion\")\n",
    "    map_CensusOSVersion(df, \"Census_OSVersion\")\n",
    "    map_OsVer(df, \"OsVer\")\n",
    "    map_OsBuildLab(df, \"OsBuildLab\")    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, df): #in_file):\n",
    "        self.df = df #pd.read_csv(in_file, dtype=dtypes)\n",
    "        #print(\"Completed read operation for\", in_file)\n",
    "        #self.reduce_mem()\n",
    "        gc.collect()\n",
    "        self.make_subsets(self.df)\n",
    "        self.encode_it()\n",
    "        self.transform_df(self.df, self.nominal_cols)\n",
    "        self.std_norm()\n",
    "        \n",
    "    \n",
    "    def reduce_mem(self, verbose=True):\n",
    "        start_mem = self.df.memory_usage().sum() / 1024**2\n",
    "        print('-- attempting to reduce memory. memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            col_type = self.df[col].dtype\n",
    "\n",
    "            if col_type != object and str(col_type) != 'category':\n",
    "                c_min = self.df[col].min()\n",
    "                c_max = self.df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        self.df[col] = self.df[col].astype(np.int64)  \n",
    "                # leave floats alone because the downcasting is messing up our mapped values\n",
    "                #else:\n",
    "                #    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                #        df[col] = df[col].astype(np.float16)\n",
    "                #    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                #        df[col] = df[col].astype(np.float32)\n",
    "                #    else:\n",
    "                #        df[col] = df[col].astype(np.float64)\n",
    "                else:\n",
    "                    if str(col_type)[:5] != 'float':\n",
    "                        self.df[col] = self.df[col].astype('category')\n",
    "\n",
    "        end_mem = self.df.memory_usage().sum() / 1024**2\n",
    "        print('-- memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        print('-- decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def make_subsets(self, df):\n",
    "        print(\"-- making subsets ...\")\n",
    "        numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        self.numeric_cols = [c for c,v in self.df.dtypes.items() if v in numerics and c in self.df.columns]\n",
    "        self.nominal_cols = [c for c in self.df.columns if (c not in self.numeric_cols)]\n",
    "#         # Andrew - still need to fix this\n",
    "#         self.nominal_cols.remove('SmartScreen')\n",
    "        self.binary_cols = [c for c in self.df.columns if (self.df[c].nunique() == 2 and c not in self.nominal_cols)]\n",
    "        self.unary_cols = [c for c in self.df.columns if (self.df[c].nunique() == 1 and c not in self.nominal_cols)]\n",
    "        if \"HasDetections\" in df.columns:\n",
    "            self.labels = df[\"HasDetections\"].values\n",
    "        print(\"-- subsets are complete\")\n",
    "        return\n",
    "\n",
    "    def transform_df(self, in_df, nominal_cols):\n",
    "        print(\"-- datatype transformation ...\")\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        tmp_df = in_df[nominal_cols].apply(le.fit_transform)\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int8].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int16].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int32].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.int64].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float16].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float32].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df.loc[:, in_df.dtypes == np.float64].columns:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        for c in in_df[in_df.select_dtypes(bool).columns]:\n",
    "            tmp_df[c] = in_df[c]\n",
    "        self.df = tmp_df\n",
    "        print(\"-- completed transforming dtypes\")\n",
    "        return\n",
    "\n",
    "    def std_norm(self):\n",
    "        print(\"-- scaling ...\")\n",
    "        col_to_std = ['AVProductStatesIdentifier',\n",
    "                      'CountryIdentifier',\n",
    "                      'CityIdentifier',\n",
    "                      'GeoNameIdentifier',\n",
    "                      'LocaleEnglishNameIdentifier',\n",
    "                      'OsBuild',\n",
    "                      'IeVerIdentifier',\n",
    "                      'Census_OEMNameIdentifier',\n",
    "                      'Census_OEMModelIdentifier',\n",
    "                      'Census_ProcessorCoreCount',\n",
    "                      'Census_ProcessorModelIdentifier',\n",
    "                      'Census_PrimaryDiskTotalCapacity',\n",
    "                      'Census_SystemVolumeTotalCapacity',\n",
    "                      'Census_TotalPhysicalRAM',\n",
    "                      'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "                      'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "                      'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "                      'Census_InternalBatteryNumberOfCharges',\n",
    "                      'Census_OSBuildNumber',\n",
    "                      'Census_OSInstallLanguageIdentifier',\n",
    "                      'Census_OSUILocaleIdentifier',\n",
    "                      'Census_FirmwareManufacturerIdentifier',\n",
    "                      'Census_FirmwareVersionIdentifier',\n",
    "                      'Wdft_RegionIdentifier',\n",
    "                      'OsBuildLab_major',\n",
    "                      'OsBuildLab_minor',\n",
    "                      'OsBuildLab_platform',\n",
    "                      'OsBuildLab_release',\n",
    "                      'OsBuildLab_build2']\n",
    "        scaled_features = self.df.copy()\n",
    "        features = scaled_features[col_to_std]\n",
    "        scaler = StandardScaler().fit(features.values)\n",
    "        features = scaler.transform(features.values)\n",
    "        scaled_features[col_to_std] = features\n",
    "        self.df = scaled_features\n",
    "        print(\"-- completed standardization and normalization\")\n",
    "        return\n",
    "    \n",
    "    def encode_it(self):\n",
    "        print(\"-- label encoding ...\")\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for n in self.nominal_cols:\n",
    "            #print(\" ...\",n)\n",
    "            self.df[n] = le.fit_transform(self.df[n])\n",
    "        print(\"-- completed label encoding\")\n",
    "        return\n",
    "    \n",
    "    def get_encoded_data(self):\n",
    "        return self.df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved function to create a mini set from the supplied criteria (n, features, labels)\n",
    "def generate_mini(n, features, labels):\n",
    "    sample_size = n / features.shape[0]\n",
    "    reserved_size = 1-sample_size\n",
    "    X_mini, X_rest, y_mini, y_rest = train_test_split(features, labels, stratify=labels, test_size=reserved_size, random_state=0)\n",
    "    return X_mini, X_rest, y_mini, y_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create stratified train, dev and validate sets from supplied ratios \n",
    "def generate_train_dev_validate_sets(train_ratio, test_ratio, features, labels):\n",
    "    reserved_size = 1-train_ratio\n",
    "    X_train, X_rest, y_train, y_rest =  \\\n",
    "        train_test_split(features, labels, stratify=labels, test_size=reserved_size, random_state=0)\n",
    "    reserved_size = 1 - (test_ratio / reserved_size)\n",
    "    X_dev, X_validate, y_dev, y_validate = \\\n",
    "        train_test_split(X_rest, y_rest, stratify=y_rest, test_size=reserved_size, random_state=0)\n",
    "    return X_train, X_dev, X_validate, y_train, y_dev, y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function for saving frames\n",
    "#\n",
    "\n",
    "def save_encoded_files(df, name):\n",
    "    \n",
    "    # save the file\n",
    "    df.to_csv(\"data/\"+name+\"_encoded.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# below here is diagnostic and test functionality, invoke as needed\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our dtypes for loading the file back when we need it\n",
    "def dump_final_types(df):\n",
    "    for dtype in df.dtypes.items():\n",
    "        print(\"'{:} '{:}',\".format((dtype[0] + \"':\").ljust(54), dtype[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unit testing the version mapping routines\n",
    "def ver_func_unit_test():\n",
    "    unitTestData = {'EngineVersion':['1.1.12902.0', '1.1.13000.0', '1.1.13103.0', '1.1.13202.0', '1.1.13303.0',\n",
    "                                     '1.1.13407.0', '1.1.13504.0', '1.1.13601.0', '1.1.13701.0', '1.1.13804.0',\n",
    "                                     '1.1.13903.0', '1.1.14003.0', '1.1.14104.0', '1.1.14202.0', '1.1.14303.0',\n",
    "                                     '1.1.14305.0', '1.1.14306.0', '1.1.14405.2', '1.1.14500.5', '1.1.14600.4',\n",
    "                                     '1.1.14700.5', '1.1.14800.1', '1.1.14800.3', '1.1.14901.3', '1.1.14901.4',\n",
    "                                     '1.1.15000.1', '1.1.15000.2', '1.1.15100.1', '1.1.15200.1', '1.1.15300.5',\n",
    "                                     '1.1.15300.6', '1.1.12805.0', '1.1.13704.0', '1.1.14700.3', '1.1.14700.4',\n",
    "                                     '1.1.12101.0', '1.1.13802.0', '1.1.11502.0', '1.1.11701.0', '1.1.14002.0',\n",
    "                                     '1.1.14102.0', '1.1.14201.0', '1.1.14500.2', '1.1.13102.0', '1.1.12400.0',\n",
    "                                     '1.1.12603.0', '1.1.14103.0', '1.1.13902.0', '1.1.13504.0', '1.1.9700.0'],\n",
    "                       'AppVersion':['4.10.14393.0', '4.10.14393.1066', '4.10.14393.1198', '4.10.14393.1593',\n",
    "                                     '4.10.14393.1613', '4.10.14393.1794', '4.10.14393.2273', '4.10.14393.953',\n",
    "                                     '4.10.205.0', '4.10.209.0', '4.11.15063.0', '4.11.15063.1155',\n",
    "                                     '4.11.15063.447', '4.12.16299.15', '4.12.17007.17123', '4.12.17007.18011',\n",
    "                                     '4.12.17007.18022', '4.13.17134.1', '4.13.17134.112', '4.13.17134.191',\n",
    "                                     '4.13.17134.228', '4.14.17613.18038', '4.14.17613.18039', '4.14.17639.18041',\n",
    "                                     '4.16.17656.18052', '4.17.17686.1003', '4.18.1806.18062', '4.18.1807.18075',\n",
    "                                     '4.18.1807.20063', '4.18.1809.2', '4.5.218.0', '4.6.305.0', '4.8.10240.16384',\n",
    "                                     '4.8.10240.17071', '4.8.10240.17113', '4.8.10240.17202', '4.8.10240.17394',\n",
    "                                     '4.8.10240.17443', '4.8.10240.17609', '4.8.10240.17861', '4.8.10240.17889',\n",
    "                                     '4.8.10240.17914', '4.8.207.0', '4.9.10586.0', '4.9.10586.1045',\n",
    "                                     '4.9.10586.1106', '4.9.10586.494', '4.9.10586.589', '4.9.218.0', '4.12.17007.17121'],\n",
    "                     'AvSigVersion':['1.225.1338.0', '1.225.1947.0', '1.225.394.0', '1.227.2357.0', '1.227.2846.0',\n",
    "                                     '1.227.2939.0', '1.229.1557.0', '1.229.1669.0', '1.229.1848.0',\n",
    "                                     '1.231.1226.0', '1.231.1362.0', '1.233.1808.0', '1.235.1725.0',\n",
    "                                     '1.235.2115.0', '1.235.2586.0', '1.235.428.0', '1.237.0.0', '1.237.1259.0',\n",
    "                                     '1.237.1572.0', '1.237.1702.0', '1.237.782.0', '1.237.787.0', '1.239.1512.0',\n",
    "                                     '1.239.230.0', '1.239.37.0', '1.239.460.0', '1.239.956.0', '1.241.296.0',\n",
    "                                     '1.241.643.0', '1.245.1013.0', '1.245.1110.0', '1.245.449.0', '1.245.931.0',\n",
    "                                     '1.245.977.0', '1.247.347.0', '1.247.641.0', '1.249.1361.0', '1.249.281.0',\n",
    "                                     '1.249.557.0', '1.249.713.0', '1.249.894.0', '1.251.1027.0', '1.251.1500.0',\n",
    "                                     '1.251.170.0', '1.251.359.0', '1.251.42.0', '1.251.505.0', '1.251.878.0',\n",
    "                                     '0.0.0.0', '1.2173.1144.0'],\n",
    "                 'Census_OSVersion':['10.0.10240.16384', '10.0.10240.16397', '10.0.10240.16405',\n",
    "                                     '10.0.10240.16445', '10.0.10240.16463', '10.0.10240.16487',\n",
    "                                     '10.0.10240.16644', '10.0.10240.17071', '10.0.10240.17202',\n",
    "                                     '10.0.10240.17394', '10.0.10240.17443', '10.0.10240.17709',\n",
    "                                     '10.0.10240.17861', '10.0.10240.17889', '10.0.10240.17914', '10.0.10586.0',\n",
    "                                     '10.0.10586.1007', '10.0.10586.104', '10.0.10586.1045', '10.0.10586.1106',\n",
    "                                     '10.0.10586.1176', '10.0.10586.122', '10.0.10586.14', '10.0.10586.164',\n",
    "                                     '10.0.10586.17', '10.0.10586.218', '10.0.10586.29', '10.0.10586.3',\n",
    "                                     '10.0.10586.318', '10.0.10586.36', '10.0.10586.420', '10.0.10586.494',\n",
    "                                     '10.0.10586.545', '10.0.10586.589', '10.0.10586.63', '10.0.10586.633',\n",
    "                                     '10.0.10586.679', '10.0.10586.71', '10.0.10586.713', '10.0.10586.753',\n",
    "                                     '10.0.10586.839', '10.0.10586.873', '10.0.10586.916', '10.0.10586.962',\n",
    "                                     '10.0.14393.0', '10.0.14393.105', '10.0.14393.1066', '10.0.14393.1198',\n",
    "                                     '10.0.17134.1', '10.0.10240.16724'],\n",
    "                            'OsVer':['10.0.0.0', '10.0.0.1', '10.0.0.112', '10.0.0.2', '10.0.0.22', '10.0.0.250',\n",
    "                                     '10.0.0.3', '10.0.0.80', '10.0.0.96', '10.0.1.0', '10.0.1.144', '10.0.1.244',\n",
    "                                     '10.0.1.44', '10.0.153.153', '10.0.16.0', '10.0.16.36', '10.0.19.80',\n",
    "                                     '10.0.2.0', '10.0.2.80', '10.0.2.86', '10.0.21.0', '10.0.23.0', '10.0.26.128',\n",
    "                                     '10.0.3.0', '10.0.3.232', '10.0.3.80', '10.0.32.0', '10.0.32.72', '10.0.4.0',\n",
    "                                     '10.0.4.80', '10.0.48.0', '10.0.5.0', '10.0.5.117', '10.0.5.18', '10.0.6.0',\n",
    "                                     '10.0.64.150', '10.0.7.0', '10.0.7.101', '10.0.7.80', '10.0.72.0', '10.0.8.0',\n",
    "                                     '10.0.80.0', '6.1.0.0', '6.1.0.112', '6.1.0.128', '6.1.1.0', '6.1.16.36',\n",
    "                                     '6.1.2.0', '6.1.3.0', '6.1.4.0'],\n",
    "                       'OsBuildLab':['10240.16384.amd64fre.th1.150709-1700',\n",
    "                                     '10240.16393.amd64fre.th1_st1.150717-1719',\n",
    "                                     '10240.16393.x86fre.th1_st1.150717-1719',\n",
    "                                     '10240.16431.amd64fre.th1.150810-2333',\n",
    "                                     '10240.16431.x86fre.th1.150810-2333',\n",
    "                                     '10240.16463.amd64fre.th1.150819-1946',\n",
    "                                     '10240.17071.amd64fre.th1.160802-1852',\n",
    "                                     '10240.17113.amd64fre.th1.160906-1755',\n",
    "                                     '10240.17202.amd64fre.th1_st1.161118-1836',\n",
    "                                     '10240.17394.amd64fre.th1_st1.170427-1347',\n",
    "                                     '10240.17443.amd64fre.th1.170602-2340',\n",
    "                                     '10240.17443.x86fre.th1.170602-2340', '10240.17709.x86fre.th1.171130-0900',\n",
    "                                     '10240.17861.amd64fre.th1.180427-1806',\n",
    "                                     '10240.17889.amd64fre.th1_st1.180529-1823',\n",
    "                                     '10240.17914.amd64fre.th1.180627-1911',\n",
    "                                     '10586.0.amd64fre.th2_release.151029-1700',\n",
    "                                     '10586.0.x86fre.th2_release.151029-1700',\n",
    "                                     '10586.1007.amd64fre.th2_release.170706-2002',\n",
    "                                     '10586.103.amd64fre.th2_release.160126-1819',\n",
    "                                     '10586.1045.amd64fre.th2_release.170728-1941',\n",
    "                                     '10586.1045.x86fre.th2_release.170728-1941',\n",
    "                                     '10586.11.amd64fre.th2_release.151112-1900',\n",
    "                                     '10586.1106.amd64fre.th2_release.170904-1742',\n",
    "                                     '10586.1176.amd64fre.th2_release_sec.170913-1848',\n",
    "                                     '10586.1176.x86fre.th2_release_sec.170913-1848',\n",
    "                                     '10586.122.amd64fre.th2_release_inmarket.160222-1549',\n",
    "                                     '10586.162.amd64fre.th2_release_sec.160223-1728',\n",
    "                                     '10586.162.x86fre.th2_release_sec.160223-1728',\n",
    "                                     '10586.17.amd64fre.th2_release.151121-2308',\n",
    "                                     '10586.212.amd64fre.th2_release_sec.160328-1908',\n",
    "                                     '10586.212.x86fre.th2_release_sec.160328-1908',\n",
    "                                     '10586.3.amd64fre.th2_release_sec.151104-1948',\n",
    "                                     '10586.306.amd64fre.th2_release_sec.160422-1850',\n",
    "                                     '10586.420.amd64fre.th2_release_sec.160527-1834',\n",
    "                                     '10586.420.x86fre.th2_release_sec.160527-1834',\n",
    "                                     '10586.494.x86fre.th2_release_sec.160630-1736',\n",
    "                                     '10586.545.amd64fre.th2_release.160802-1857',\n",
    "                                     '10586.589.amd64fre.th2_release.160906-1759',\n",
    "                                     '10586.63.amd64fre.th2_release.160104-1513',\n",
    "                                     '10586.633.amd64fre.th2_release.161004-1602',\n",
    "                                     '10586.672.amd64fre.th2_release_sec.161024-1825',\n",
    "                                     '10586.672.x86fre.th2_release_sec.161024-1825',\n",
    "                                     '10586.839.amd64fre.th2_release.170303-1605',\n",
    "                                     '10586.839.x86fre.th2_release.170303-1605',\n",
    "                                     '10586.916.amd64fre.th2_release_sec.170427-1350',\n",
    "                                     '10586.962.amd64fre.th2_release.170602-2241',\n",
    "                                     '10586.962.x86fre.th2_release.170602-2241',\n",
    "                                     '0.0.-.-.0-0',\n",
    "                                     '18238.1000.amd64fre.rs_onecore_sigma_grfx_dev.180911-1700']\n",
    "                   }\n",
    "\n",
    "    unitTestDf = pd.DataFrame(unitTestData) \n",
    "\n",
    "    # method to test (copied from the notebook)\n",
    "    # 10.0.153.153  1000.15315299999997\n",
    "\n",
    "\n",
    "    pd.options.display.float_format = '{:.14f}'.format\n",
    "    set_of_cols =['EngineVersion_combined','EngineVersion','AppVersion_combined', 'AppVersion', 'AvSigVersion_combined', 'AvSigVersion', 'Census_OSVersion_combined', 'Census_OSVersion', 'OsVer_combined', 'OsVer', 'OsBuildLab_combined', 'OsBuildLab']\n",
    "    return unitTestDf[set_of_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using big dataset\n",
      "done loading train data\n",
      "total rows in set: 8921483\n",
      "seconds elapsed: 91.0527777671814\n",
      "creating mini_initial.csv for debug purposes ...\n",
      "created mini_initial.csv data\n",
      "seconds elapsed: 97.91017484664917\n",
      "cleaning train.csv or mini_initial.csv data ...\n",
      "-- replacing weird characters ...\n",
      "-- lower-casing where appropriate ...\n",
      "-- making categories from strings that needed massaging ...\n",
      "-- adding categories ..\n",
      "-- replacing selected NA values\n",
      "-- converting columns to int ...\n",
      "-- mapping version numbers ...\n",
      "encoding train data ...\n",
      "-- making subsets ...\n",
      "-- subsets are complete\n",
      "-- label encoding ...\n",
      "-- completed label encoding\n",
      "-- datatype transformation ...\n",
      "-- completed transforming dtypes\n",
      "-- scaling ...\n",
      "-- completed standardization and normalization\n",
      "done cleaning and encoding train data\n",
      "seconds elapsed: 551.5067896842957\n",
      "generating smaller stratified sets ...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# main code part one: train dataset\n",
    "#\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "if debug:\n",
    "    print(\"using mini_initial.csv dataset\")\n",
    "    filename = \"mini_initial\"\n",
    "else:        \n",
    "    print(\"using big dataset\")\n",
    "    filename = \"train\"\n",
    "    \n",
    "#\n",
    "# initial load and casting to desired types\n",
    "#\n",
    "\n",
    "df = load_data(filename)\n",
    "print(\"done loading train data\")\n",
    "print(\"total rows in set:\", len(df))\n",
    "print(\"seconds elapsed:\", time.time()-start)\n",
    "\n",
    "#\n",
    "# make mini_initial, before cleaning and dropping, if necessary (to debug wrangler code)\n",
    "#\n",
    "   \n",
    "if not debug:\n",
    "    print(\"creating mini_initial.csv for debug purposes ...\")\n",
    "    df2 = df.sample(100000, random_state=123)\n",
    "    df2.to_csv(\"data/mini_initial.csv\", index=False)\n",
    "    print(\"created mini_initial.csv data\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n",
    "    \n",
    "#\n",
    "# main work is done here\n",
    "#\n",
    "    \n",
    "print(\"cleaning train.csv or mini_initial.csv data ...\")\n",
    "df = clean_data(df)\n",
    "print(\"encoding train data ...\")\n",
    "df = Encoder(df).get_encoded_data()\n",
    "print(\"done cleaning and encoding train data\")\n",
    "print(\"seconds elapsed:\", time.time()-start)\n",
    "\n",
    "print(\"generating smaller stratified sets ...\")\n",
    "\n",
    "# generate stratified data sets using supplied ratios to create the sets\n",
    "df_train, df_dev, df_validate, train_labels, dev_labels, validate_labels = \\\n",
    "    generate_train_dev_validate_sets(.7, .15, df, df['HasDetections'])\n",
    "\n",
    "df=[] # release df from memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mini_train: (312251, 151)\n",
      "shape of mini_dev: (66911, 151)\n",
      "379162\n",
      "shape of mini_test: (66911, 151)\n",
      "379162\n",
      "done making mini sets\n",
      "seconds elapsed: 679.0455458164215\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# create mini_ files for model development\n",
    "#\n",
    "mini_ratio = .05\n",
    "\n",
    "mini_train, remaining, mini_train_labels, remaining_labels = \\\n",
    "    generate_mini(df_train.shape[0]*mini_ratio, df_train, df_train['HasDetections'])\n",
    "\n",
    "mini_dev, remaining, mini_dev_labels, remaining_labels = \\\n",
    "    generate_mini(df_dev.shape[0]*mini_ratio, df_dev, df_dev['HasDetections'])\n",
    "\n",
    "mini_validate, remaining, mini_validate_labels, remaining_labels = \\\n",
    "    generate_mini(df_validate.shape[0]*mini_ratio, df_validate, df_validate['HasDetections'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mini_train: (312251, 151)\n",
      "shape of mini_dev: (66911, 151)\n",
      "shape of mini_validate: (66911, 151)\n",
      "\n",
      "checking symmetric difference between mini_dev and mini_train: 379162\n",
      "-- total unique machine ids after recombining both sets: 379162\n",
      "-- original length of mini_dev + length of mini_train: 379162\n",
      "\n",
      "checking symmetric difference between mini_validate and mini_train: 379162\n",
      "-- total unique machine ids after recombining both sets: 379162\n",
      "-- original length of mini_validate + length of mini_train: 379162\n",
      "\n",
      "checking symmetric difference between mini_dev and mini_validate: 133822\n",
      "-- total unique machine ids after recombining both sets: 133822\n",
      "-- original length of mini_dev + length of mini_validate: 133822\n",
      "\n",
      "done making mini sets\n",
      "seconds elapsed: 1928.0604047775269\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of mini_train:\",mini_train.shape)\n",
    "print(\"shape of mini_dev:\",mini_dev.shape)\n",
    "print(\"shape of mini_validate:\",mini_validate.shape)\n",
    "print(\"\\nchecking symmetric difference between mini_dev and mini_train:\", len(set(mini_train['MachineIdentifier']).symmetric_difference(mini_dev['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_train['MachineIdentifier'], mini_dev['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_dev + length of mini_train:\", mini_dev.shape[0] + mini_train.shape[0])\n",
    "print(\"\\nchecking symmetric difference between mini_validate and mini_train:\", len(set(mini_train['MachineIdentifier']).symmetric_difference(mini_validate['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_train['MachineIdentifier'], mini_validate['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_validate + length of mini_train:\", mini_validate.shape[0] + mini_train.shape[0])\n",
    "print(\"\\nchecking symmetric difference between mini_dev and mini_validate:\", len(set(mini_dev['MachineIdentifier']).symmetric_difference(mini_validate['MachineIdentifier'])))\n",
    "print(\"-- total unique machine ids after recombining both sets:\", pd.concat([mini_dev['MachineIdentifier'], mini_validate['MachineIdentifier']]).nunique())\n",
    "print(\"-- original length of mini_dev + length of mini_validate:\", mini_validate.shape[0] + mini_dev.shape[0])\n",
    "print(\"\\ndone making mini sets\")\n",
    "print(\"seconds elapsed:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving mini_train_encoded ...\n",
      "saving mini_dev_encoded ...\n",
      "saving mini_validate_encoded ...\n",
      "done saving mini files\n",
      "seconds elapsed: 2154.518833875656\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# save encoded mini files\n",
    "# save function will add \"data/\" and \"_encoded.csv\"\n",
    "#\n",
    "\n",
    "if save_data:\n",
    "    print(\"saving mini_train_encoded ...\")\n",
    "    save_encoded_files(mini_train, \"mini_train\")\n",
    "    print(\"saving mini_dev_encoded ...\")\n",
    "    save_encoded_files(mini_dev, \"mini_dev\")\n",
    "    print(\"saving mini_validate_encoded ...\")\n",
    "    save_encoded_files(mini_validate, \"mini_validate\")\n",
    "    print(\"done saving mini files\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving train_encoded ...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# save encoded full files\n",
    "# save function will add \"data/\" and \"_encoded.csv\"\n",
    "#\n",
    "\n",
    "if save_data:\n",
    "    print(\"saving train_encoded ...\")\n",
    "    save_encoded_files(df_train, \"train\")\n",
    "    print(\"done saving encoded train file\")\n",
    "\n",
    "    print(\"saving dev_encoded ...\")\n",
    "    save_encoded_files(df_dev, \"dev\")\n",
    "    print(\"done saving encoded dev file\")\n",
    "\n",
    "    print(\"saving validate_encoded ...\")\n",
    "    save_encoded_files(df_validate, \"validate\")\n",
    "    print(\"done saving encoded validate file\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# part two: large test dataset\n",
    "#\n",
    "    \n",
    "if not debug:\n",
    "    print(\"loading test data ...\")\n",
    "    df_test = load_data(\"test\")\n",
    "    print(\"done loading test data\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n",
    "    print(\"total rows in test set:\", len(df_test))\n",
    "    print(\"cleaning large test data ...\")\n",
    "    df_test = clean_data(df_test)\n",
    "    print(\"encoding large test data ...\")\n",
    "    df_test = Encoder(df_test).get_encoded_data()\n",
    "    print(\"done cleaning and encoding large test data\")\n",
    "# commenting this out so it doesn't happen\n",
    "# since this small test set is not a subset of the larger test set\n",
    "# and having it around maybe causing confusion\n",
    "#else:\n",
    "#    print(\"faking large test data ...\")\n",
    "#    df_test_large = df_test_small.copy()   \n",
    "print(\"seconds elapsed:\", time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    print(\"saving encoded large test data ...\")\n",
    "    save_encoded_files(df_test, \"test\")\n",
    "    print(\"done saving encoded files\")\n",
    "    print(\"seconds elapsed:\", time.time()-start)\n",
    "\n",
    "#\n",
    "# at this point, the sets are in the following dataframes:\n",
    "#\n",
    "# df_train, df_dev, df_test_small: \n",
    "#    main large sets, all derived from train.csv (unles debugging)\n",
    "# mini_train, mini_dev, mini_test: \n",
    "#    really small files for development, all derived from train.csv (unless debugging)\n",
    "# df_test_large: \n",
    "#    test.csv dataset (or same as df_test_small, if debugging)\n",
    "#\n",
    "     \n",
    "print(\"all done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_final_types(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
